{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8VSns6fO6Pg"
   },
   "source": [
    "**Seeding for reproducibility**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JSu8kpnEHDPB"
   },
   "outputs": [],
   "source": [
    "# Set seeds for reproducibility\n",
    "import random\n",
    "random.seed(0)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eyqk5_8AO1Kr"
   },
   "source": [
    "**Importing the dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "16dILovOOFy0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7gAnTOlEPR8a"
   },
   "source": [
    "**Data Curation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GT4tQUqBs90l"
   },
   "source": [
    "Upload the kaggle.json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_5Oa9WPtfXr",
    "outputId": "79a1b2c7-ca9c-4a89-febe-17abc7f399d3"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'(' was never closed (2724643422.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[4], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(os.listdir(\"plantvillage dataset\")\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m '(' was never closed\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"plantvillage dataset\")\n",
    "\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/segmented\")))\n",
    "print(os.listdir(\"plantvillage dataset/segmented\")[:5])\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/color\")))\n",
    "print(os.listdir(\"plantvillage dataset/color\")[:5])\n",
    "\n",
    "print(len(os.listdir(\"plantvillage dataset/grayscale\")))\n",
    "print(os.listdir(\"plantvillage dataset/grayscale\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snyC_-2jt0z3"
   },
   "source": [
    "**Number of Classes = 38**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CFR52Pk6tp2U",
    "outputId": "4917ce76-17f2-4103-85ca-14d2af84dc06"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'plantvillage dataset/color/Grape___healthy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplantvillage dataset/color/Grape___healthy\u001b[39m\u001b[38;5;124m\"\u001b[39m)))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplantvillage dataset/color/Grape___healthy\u001b[39m\u001b[38;5;124m\"\u001b[39m)[:\u001b[38;5;241m5\u001b[39m])\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'plantvillage dataset/color/Grape___healthy'"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir(\"plantvillage dataset/color/Grape___healthy\")))\n",
    "print(os.listdir(\"plantvillage dataset/color/Grape___healthy\")[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JhEi6mbpt4aD"
   },
   "source": [
    "**Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WlqvsdtBttrh"
   },
   "outputs": [],
   "source": [
    "# Dataset Path\n",
    "base_dir = 'plantvillage '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "XQxHLLbKt6oF",
    "outputId": "960d3327-8801-4a10-e6c5-f5551337a781"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read the image\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m img \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(img\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Display the image\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\matplotlib\\image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1524\u001b[0m         )\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_open(fname) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'"
     ]
    }
   ],
   "source": [
    "image_path = 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img.shape)\n",
    "# Display the image\n",
    "plt.imshow(img)\n",
    "plt.axis('off')  # Turn off axis numbers\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YVgo1I9sDP6B",
    "outputId": "302d2d4b-6f7c-4ddf-ab9e-a9d6bd738b7e"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Read the image\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m img \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(img)\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\matplotlib\\image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1519\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[0;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1524\u001b[0m         )\n\u001b[1;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_open(fname) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   1527\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\PIL\\Image.py:3247\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3244\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3247\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3248\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3250\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'"
     ]
    }
   ],
   "source": [
    "image_path = 'plantvillage dataset/color/Apple___Cedar_apple_rust/025b2b9a-0ec4-4132-96ac-7f2832d0db4a___FREC_C.Rust 3655.JPG'\n",
    "\n",
    "# Read the image\n",
    "img = mpimg.imread(image_path)\n",
    "\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w6S1jYo0u5o-"
   },
   "outputs": [],
   "source": [
    "# Image Parameters\n",
    "img_size = 224\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lcovy3vxvf31"
   },
   "source": [
    "**Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zoJjajTcvTae"
   },
   "outputs": [],
   "source": [
    "# Image Data Generators\n",
    "data_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2  # Use 20% of data for validation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pnwsA5IPvWNG",
    "outputId": "be155ed6-aa77-4f28-c202-94fba6ea59bd"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] Le chemin d’accès spécifié est introuvable: 'plantvillage '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train Generator\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m data_gen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m      3\u001b[0m     base_dir,\n\u001b[0;32m      4\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(img_size, img_size),\n\u001b[0;32m      5\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m      6\u001b[0m     subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1138\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow_from_directory\u001b[39m(\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1122\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1136\u001b[0m     keep_aspect_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1137\u001b[0m ):\n\u001b[1;32m-> 1138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1139\u001b[0m         directory,\n\u001b[0;32m   1140\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1141\u001b[0m         target_size\u001b[38;5;241m=\u001b[39mtarget_size,\n\u001b[0;32m   1142\u001b[0m         color_mode\u001b[38;5;241m=\u001b[39mcolor_mode,\n\u001b[0;32m   1143\u001b[0m         keep_aspect_ratio\u001b[38;5;241m=\u001b[39mkeep_aspect_ratio,\n\u001b[0;32m   1144\u001b[0m         classes\u001b[38;5;241m=\u001b[39mclasses,\n\u001b[0;32m   1145\u001b[0m         class_mode\u001b[38;5;241m=\u001b[39mclass_mode,\n\u001b[0;32m   1146\u001b[0m         data_format\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_format,\n\u001b[0;32m   1147\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1148\u001b[0m         shuffle\u001b[38;5;241m=\u001b[39mshuffle,\n\u001b[0;32m   1149\u001b[0m         seed\u001b[38;5;241m=\u001b[39mseed,\n\u001b[0;32m   1150\u001b[0m         save_to_dir\u001b[38;5;241m=\u001b[39msave_to_dir,\n\u001b[0;32m   1151\u001b[0m         save_prefix\u001b[38;5;241m=\u001b[39msave_prefix,\n\u001b[0;32m   1152\u001b[0m         save_format\u001b[38;5;241m=\u001b[39msave_format,\n\u001b[0;32m   1153\u001b[0m         follow_links\u001b[38;5;241m=\u001b[39mfollow_links,\n\u001b[0;32m   1154\u001b[0m         subset\u001b[38;5;241m=\u001b[39msubset,\n\u001b[0;32m   1155\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m   1156\u001b[0m         dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1157\u001b[0m     )\n",
      "File \u001b[1;32mC:\\Nouveau dossier\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:453\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[0;32m    452\u001b[0m     classes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 453\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(os\u001b[38;5;241m.\u001b[39mlistdir(directory)):\n\u001b[0;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    455\u001b[0m             classes\u001b[38;5;241m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] Le chemin d’accès spécifié est introuvable: 'plantvillage '"
     ]
    }
   ],
   "source": [
    "# Train Generator\n",
    "train_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='training',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtxNLvmbvYNX",
    "outputId": "a60d0b2a-bba4-4595-d5e1-e9f6978ddbab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10849 images belonging to 38 classes.\n"
     ]
    }
   ],
   "source": [
    "# Validation Generator\n",
    "validation_generator = data_gen.flow_from_directory(\n",
    "    base_dir,\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    subset='validation',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fE4vUKMkviT8"
   },
   "source": [
    "**Convolutional Neural Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "VUsvwveevZ-m"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models, layers\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m32\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(img_size, img_size, \u001b[38;5;241m3\u001b[39m)))\n\u001b[0;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mMaxPooling2D(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(layers\u001b[38;5;241m.\u001b[39mConv2D(\u001b[38;5;241m64\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'img_size' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import models, layers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size, img_size, 3)))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(train_generator.num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T9qJo-GSvoIB",
    "outputId": "56ed059c-85f2-4490-8dfc-63e25516d2ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 111, 111, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 54, 54, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               47776000  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 38)                9766      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 47805158 (182.36 MB)\n",
      "Trainable params: 47805158 (182.36 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "PKi-ot0xvpC8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dCBezWyLv1hF"
   },
   "source": [
    "**Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSvHhJqevyjE",
    "outputId": "51052757-e403-4ed0-87b0-42ff1ff6451b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ASUS\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      " 426/1358 [========>.....................] - ETA: 26:12 - loss: 1.7003 - accuracy: 0.5813"
     ]
    }
   ],
   "source": [
    "# Training the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
    "    epochs=5,  # Number of epochs\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size  # Validation steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RjQfNu7QwZjw"
   },
   "source": [
    "**Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9SRLiOMv3qm",
    "outputId": "c5680df7-67df-41c9-84c7-bee0b17b7f0c"
   },
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "print(\"Evaluating model...\")\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator, steps=validation_generator.samples // batch_size)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "ZxP07UNywYPj",
    "outputId": "228b5e7e-2a21-4cbb-931f-55708ed0cc34"
   },
   "outputs": [],
   "source": [
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIeDSJa5xkpy"
   },
   "source": [
    "**Building a Predictive System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0onhRrVkv9-M"
   },
   "outputs": [],
   "source": [
    "# Function to Load and Preprocess the Image using Pillow\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    # Load the image\n",
    "    img = Image.open(image_path)\n",
    "    # Resize the image\n",
    "    img = img.resize(target_size)\n",
    "    # Convert the image to a numpy array\n",
    "    img_array = np.array(img)\n",
    "    # Add batch dimension\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    # Scale the image values to [0, 1]\n",
    "    img_array = img_array.astype('float32') / 255.\n",
    "    return img_array\n",
    "\n",
    "# Function to Predict the Class of an Image\n",
    "def predict_image_class(model, image_path, class_indices):\n",
    "    preprocessed_img = load_and_preprocess_image(image_path)\n",
    "    predictions = model.predict(preprocessed_img)\n",
    "    predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "    predicted_class_name = class_indices[predicted_class_index]\n",
    "    return predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZkE2k6gwgOR"
   },
   "outputs": [],
   "source": [
    "# Create a mapping from class indices to class names\n",
    "class_indices = {v: k for k, v in train_generator.class_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3dja767dwzFH",
    "outputId": "d0344da3-a583-459c-94dc-d63027b1f4a5"
   },
   "outputs": [],
   "source": [
    "class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StM3_I3UwjFV"
   },
   "outputs": [],
   "source": [
    "# saving the class names as json file\n",
    "json.dump(class_indices, open('class_indices.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kJb9gQGRw2Ln",
    "outputId": "f329cc1c-2945-416a-f42d-174a433ff60c"
   },
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "image_path = '/content/test_apple_black_rot.JPG'\n",
    "#image_path = '/content/test_blueberry_healthy.jpg'\n",
    "#image_path = '/content/test_potato_early_blight.jpg'\n",
    "predicted_class_name = predict_image_class(model, image_path, class_indices)\n",
    "\n",
    "# Output the result\n",
    "print(\"Predicted Class Name:\", predicted_class_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBkknsKMyDbs"
   },
   "source": [
    "**Save the model to Google drive or local**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OfoTNemcxjk5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J8ByAMH6ykbN",
    "outputId": "8836c7a9-6d35-421f-b36c-f6fb50fd5cf7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('plant_disease_prediction_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ln01Rmj0L8Hg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
